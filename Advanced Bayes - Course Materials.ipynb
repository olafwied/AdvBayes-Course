{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scalable Methods for Bayesian Machine Learning and Probabilistic Inference\n",
    "## And other advanced topics\n",
    "\n",
    "## © Olaf Wied 2018\n",
    "\n",
    "Note that this is intended for an advanced audience. Background in machine learning and deep learning, linear algebra and probability theory is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018\n",
    "## Scalable Methods for Bayesian Machine Learning and Probabilistic Inference\n",
    "\n",
    "# Outline\n",
    "### [Part I - Short Recap of Bayesian Basics](#/2)\n",
    "- Bayes Theorem\n",
    "- Bayesian Inference\n",
    "- Generative vs Discriminative Models\n",
    "- Bayesian Statistics\n",
    "- Priors\n",
    "- Frequentist Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018\n",
    "\n",
    "### [Part II - Latent Variable Models and the EM Algorithm](#/11)\n",
    "\n",
    "- Kullback-Leibler Divergence\n",
    "- Latent Variable Models\n",
    "- Example: Mixture Models\n",
    "- EM Algorithm, E-Step and M-Step\n",
    "- Large Scale EM\n",
    "- Variational and Stochastic Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018\n",
    "### Part III - Scalable Methods for Bayesian Learning\n",
    "- Probabilistic PCA\n",
    "- Variational Autoencoders\n",
    "- The Reparametrization Trick\n",
    "- Generative Models and Adverserial Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018\n",
    "### Part IV - Gaussian Processes and Optimization\n",
    "- Gaussian Processes\n",
    "- Bayesian Optimization\n",
    "- MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018\n",
    "### Part V - Bayesian Deep Learning\n",
    "- Bayesian Neural Networks\n",
    "- Variational Dropout\n",
    "- Sparse Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018\n",
    "# Part I - Recap of Bayesian ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Bayes' Theorem\n",
    "\n",
    "\n",
    "$$p(y|x) = \\frac{p(x|y)p(y)}{p(x)} = \\frac{p(x|y)p(y)}{\\int{p(x|y)p(y) dy}}$$\n",
    "\n",
    "or in words \n",
    "\n",
    "$$Posterior = \\frac{Likelihood \\cdot Prior}{Evidence}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# The Inference Problem\n",
    "\n",
    "#### Problem\n",
    "Given data $X = (x_1,\\ldots,x_n)$ (iid) from $p(x|\\theta)$, infere $\\theta$.\n",
    "\n",
    "#### MLE (Maximum Likelihood Estimation)\n",
    "$$\\theta_{ML} = \\arg \\max \\prod_{i=1}^n{p(x_i|\\theta)} = \\arg \\max \\sum_{i=1}^n{\\log p(x_i|\\theta)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# The Inference Problem\n",
    "\n",
    "#### Problem\n",
    "Given data $X = (x_1,\\ldots,x_n)$ (iid) from $p(x|\\theta)$, infere $\\theta$.\n",
    "\n",
    "#### Bayesian Inference\n",
    "Encode uncertainty about $\\theta$ in terms of a **prior distribution $p(\\theta)$** and apply Bayes' theorem:\n",
    "\n",
    "$$p(\\theta|X) = \\frac{\\prod_{i=1}^n p(x_i|\\theta)p(\\theta)}{\\int \\prod_{i=1}^n p(x_i|\\theta)p(\\theta) d\\theta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bayesian Inference provides a full *posterior* distribution over $\\theta$. **Computing the mode is called \"Poor Man's Bayes\" and gives the MAP (Maximum A Posteriori) estimate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# The Inference Problem\n",
    "\n",
    "#### Bayesian Inference\n",
    "Note that the evidence does not depend on $\\theta$ and therefore is irrelevant for computing the MAP estimate: $$\\theta_{MAP} = \\arg \\max p(x|\\theta)p(\\theta) = \\arg \\max \\{\\log p(x|\\theta) + \\log p(\\theta) \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Note further that, while the likelihood depends exponentially on $n$, the prior remains constant. Hence, eventually, the data will *overwhelm the prior* and the MAP will converge towards the MLE.** Likewise, the posterior will become peaked around the MAP estimate.\n",
    "\n",
    "It is often the case, that when $n$ grows, frequentist and Bayesian perspective will yield the same result! They do not contradict each other. You should have both tools in your toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Note on MAP estimation\n",
    "\n",
    "The MAP is a popular point estimate because calculating the mode (other than the mean or median for example) is an **optimization problem**, for which we have many efficient algorithms available. However, the are **drawbacks** and I want to point out a few as a reference:\n",
    "\n",
    "- Mean or median often summarize the posterior distribution better than the mode.\n",
    "- Point estimates lack a measure of uncertainty.\n",
    "- This can lead to overfitting.\n",
    "- The MAP estimate depends on the parametrization of the distribution: Let $y=f(x)$, then $\\bar x = \\arg \\max p_x(x)$ and $\\bar y = \\arg \\max p_{y}(y)$ does not imply $\\bar y = f(\\bar x)$.\n",
    "\n",
    "(See, for example, K.P. Murphy: Machine Learning, ch. 5.2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Generative vs Discriminative Models\n",
    "\n",
    "#### Generative Models\n",
    "Model the joint distribution $p(x,y,\\theta) = p(x,y|\\theta)p(\\theta)$. This means that once we have a trained model we can generate new data $(x,y)$. \n",
    "\n",
    "Examples are *Naive Bayes* or *Generative Adversarial Networks (GANs)*.\n",
    "\n",
    "Generative models can be difficult to train, because the feature space $X$ is usually much more complicated than the label space $Y$, e.g.\n",
    "\n",
    "- In image classification, the space of all images $X$ is much more complicated than the $Y$ space of image classes.\n",
    "- However, there are other examples. In machine translation $X$ and $Y$ space are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Generative vs Discriminative Models\n",
    "\n",
    "#### Discriminative Models\n",
    "If we directly model the class posterior, e.g. $p(y=c, \\theta |x)$, we do not need to know about the distribution of the observed variables. This is called a discriminant classifier. We usually assume that the prior over the model parameters $\\theta$ does not depend on $X$, thus\n",
    "\n",
    "$$p(y,\\theta | x) = p(y | x,\\theta)p(\\theta)$$\n",
    "\n",
    "A basic example is *Logistic Regression*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Generative vs Discriminative Models\n",
    "\n",
    "Both have advantages and disadvantages! Again, have both in your toolbox.\n",
    "\n",
    "Generative Classifiers impose more strict assumptions on the model. If the assumptions are correct, generatives models can be trained **faster and with less data**. But, joint distributions are harder to estimate and lead to uncertainty, therefore **discriminative models are often more accurate**. \n",
    "\n",
    "Models like Naive Bayes can be trained extremely easily by simply counting. However, the strong assumptions are often not met and lead to ill-calibrated probability outputs.\n",
    "\n",
    "Generative models, however, have the advantage to be able to **deal with missing data** and can be extended more easily to semi-supervised learning. (See, for example, B. Marlin (2008): Missing Data Problems in Machine Learning)\n",
    "\n",
    "Discriminative models, since they do not care about the distribution of the data, have the advantage that they allow arbitrary **feature preprocessing**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Bayesian Statistics\n",
    "\n",
    "#### Sequential Learning\n",
    "Bayesian inference can be done sequentially or in batches which makes it a great candidate for **online or minibatch learning**, the preferred method when dealing with large datasets.\n",
    "\n",
    "- Define Prior\n",
    "\n",
    "```R\n",
    "Posterior <- Likelihood x Prior\n",
    "(New) Prior <- Posterior\n",
    "```\n",
    "\n",
    "- Observe new data\n",
    "\n",
    "```R\n",
    "Update Likelihood\n",
    "(New) Posterior <- Likelihood x (New) Prior\n",
    "```\n",
    "\n",
    "- Repeat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Bayesian Statistics\n",
    "\n",
    "#### Bayesian Inference as Ensemble Learning\n",
    "\n",
    "Suppose we work with training data $(X_{tr}, Y_{tr})$ and a discriminator $p(Y,\\theta | X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Training the model consists of calculating \n",
    "\n",
    "$$p(\\theta | X_{tr}, Y_{tr}) = \\frac{p(Y_{tr}|X_{tr},\\theta)p(\\theta)}{\\int p(Y_{tr}|X_{tr},\\theta)p(\\theta)d\\theta}$$\n",
    "\n",
    "This is an **ensemble** of models over the distribution of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "At test time, we perform **model averageing** via the posterior over $\\theta$:\n",
    "\n",
    "$$p(y_{test}|x_{test},X_{tr},Y_{tr}) = \\int p(y_{test}|x_{test},\\theta)p(\\theta|X_{tr},Y_{tr})d\\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Bayesian Statistics\n",
    "\n",
    "#### Intractability\n",
    "Model averageing outperforms a single model in the $\\theta$ family (e.g. the MAP model $\\arg \\max_{\\theta} p(\\theta|X,Y)$ or a model found through cross-validation) since the full posterior contains all information about $X$ and $Y$ that the model can detect.\n",
    "\n",
    "However, the **integrals** that appear during training and test are usually **intractable**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There is one family of exception: conjugate priors! We will talk more about these in the next segment (to the right).\n",
    "\n",
    "For now, remember that distributions $p(y)$ and $p(x|y)$ are **conjugate** iff $p(y|x)$ belongs to the same (parametric) family as $p(y)$. If so, the formulas above will have **closed-form solutions**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Bayesian Statistics\n",
    "\n",
    "#### Intractability\n",
    "For models where this is intractable, approximate methods exist based on sampling methods like MCMC or variational apprxoimations.\n",
    "\n",
    "Variational inference is based on the idea to pick a tractable family of approximations to the posterior and then pick the one that is closest to the true posterior, e.g. by minimizing the Kulback-Leibler distance between the two.\n",
    "\n",
    "We will discuss these methods and scalable versions of them in following chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Bayesian Statistics\n",
    "\n",
    "#### Model Selection, Overfitting and Regularization\n",
    "\n",
    "As mentioned, for large datasets MAP estimates and full Bayesian posteriors lead to similar results, but they can be very different for small or ambiguous datasets. In such a case, the posterior will be vague, which leads to a very broad (or uninformative) predictive distribution. However, just using the MAP model (or *plug-in aproximation*) is simple, but can underestimate the uncertainty. The Bayesian approach has the nice property that it **starts out broad** and becomes narrower as we become more certain or see more data. This coincides better with our intuitive understanding. Starting out broadly can prevent overfitting!\n",
    "\n",
    "The Bayesian approach also has the advantage that it can **incorporate regularization** within the Bayesian framework by prescriping appropriate priors, e.g.\n",
    "\n",
    "- Lasso and Ridge Regression, for example, can be seen as specially cases with Laplace and Gaussian priors.\n",
    "- In models based on count values, like Naive Bayes for word counts, priors can naturally prevent Black-Swan type paradoxes when the model encounters a previously unseen word (which can otherwise lead to zero probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Bayesian Statistics\n",
    "\n",
    "#### Scalability\n",
    "Scalability has traditionally been an issue for Bayesian methods. However, tools have emerged that make variational and MCMC inference scalable. \n",
    "\n",
    "We will present some of these in the following chapters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Priors\n",
    "\n",
    "One hotly debated issue of Bayesian statistics is the use of priors. For Bayesians this is necessary because nobody operates in a vacuum. However, there are some ways to reduce the impact of one's prior assumptions, e.g. using **uninformative priors**.\n",
    "\n",
    "**Conjugate priors** simplify computations and are often easy to interpret. As a reference, we provide the standard example of the **beta-binomial model**, which models the **probability to see heads in a series of coin flips**. Let $X_i \\sim Ber(\\theta), \\theta \\in [0,1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Likelihood**: $p(X|\\theta) = \\theta^{N_{head}}(1-\\theta)^{N_{tail}}$, with $N_{head} \\sim Bin(N_{head}+N_{tail}, \\theta)$ (the binomial distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - The **conjugate prior** of the Bernoulli distribution is the Beta distribution\n",
    "  - $p(\\theta) \\propto \\theta^{a-1}(1-\\theta)^{b-1} \\propto Beta(\\theta|a,b)$, note that $a$ and $b$ are called hyper-parameters\n",
    "  - If we have no prior knowledge of $\\theta$ we can choose the uniform distribution which is given via $Beta(\\theta|1,1)$ (see plot below). This is a way to implement an **uninformative prior** (more later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20b755f6f28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "x = np.linspace(beta.ppf(0.01, a, b), beta.ppf(0.99, a, b), 100)\n",
    "ax.plot(x, beta.pdf(x, 1, 1),\n",
    "       'r-', lw=2, alpha=0.6, label='beta a=1 b=1')\n",
    "ax.plot(x, beta.pdf(x, 2, 2),\n",
    "       'b-', lw=2, alpha=0.6, label='beta a=2 b=2')\n",
    "ax.plot(x, beta.pdf(x, 1, 2),\n",
    "       'g-', lw=2, alpha=0.6, label='beta a=1 b=2')\n",
    "ax.plot(x, beta.pdf(x, 3, 1),\n",
    "       'y-', lw=2, alpha=0.6, label='beta a=3 b=1')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Priors\n",
    "\n",
    "- Likelihood: $p(X|\\theta) = \\theta^{N_{head}}(1-\\theta)^{N_{tail}}$, with $N_{head} \\sim Bin(N_{head}+N_{tail}, \\theta)$\n",
    "- Conjugate prior: $p(\\theta) \\propto Beta(\\theta|a,b)$\n",
    " \n",
    "- **Posterior**: Multiplying likelihood and prior amounts to adding the exponents and yields $\\propto Beta(\\theta|N_{head}+a, N_{tail}+b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The hyper-parameters of the prior, $a$ and $b$, are therefore called **pseduo-counts**. The total strength of the prior is determined by the sum of pseduo-heads and pseudo-tails $a+b$.\n",
    "\n",
    "We can see, again, how Bayesian inference works well sequentially. Updating the posterior is simply adding the new counts of heads and tails to the prior counts.\n",
    "\n",
    "Note that priors need not necessarily be **proper** distributions (i.e. integrate to 1). This is possible as long as the posterior is proper!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Priors\n",
    "#### Jeffreys prior\n",
    "\n",
    "**Jeffreys priors** are a general purpose technique to design **uninformative** priors. The key insight behind Jeffreys priors is that uninformative priors should be invariant under reparametrization. One can show that this can be achieved when the prior is proportional to the square root of the determinant of the **Fisher information**:\n",
    "\n",
    "$$ p(\\theta) \\propto \\sqrt{\\det \\mathcal{I}(\\theta)} $$\n",
    "\n",
    "Note that the Fisher information is not the only choice with this property. Also, remember that Jeffreys priors can be improper. For example, the Jeffreys prior for the Gaussian mean parameter $\\mu$ (with fixed standard deviation) is $1$ and independent of $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Priors\n",
    "#### Jeffreys prior\n",
    "\n",
    "Let's revisit the example of the beta-binomial model where we previously suggested a uniform, or $Beta(1,1)$, distribution over $[0,1]$ as an uninformative prior.\n",
    "\n",
    "We will show that the Jeffreys prior for $X \\sim Ber(\\theta)$ is actually $Beta(\\frac{1}{2},\\frac{1}{2})$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Priors\n",
    "#### Jeffreys prior\n",
    "The log-likelihood is $p(X|\\theta) = X\\log\\theta + (1-X)\\log(1-\\theta)$ with derivative $\\frac{X}{\\theta}-\\frac{1-X}{1-\\theta}$.\n",
    "The second derivative is $J(\\theta) = -\\frac{X}{\\theta^2}-\\frac{1-X}{(1-\\theta)^2}$.\n",
    "\n",
    "The Fisher information is then \n",
    "\n",
    "$$\\mathcal{I}(\\theta) = \\mathbb{E} \\left[ -J(\\theta|X) \\mid X\\sim\\theta\\right] = \\frac{\\theta}{\\theta^2} + \\frac{1-\\theta}{(1-\\theta)^2} = \\frac{1}{\\theta(1-\\theta)}$$\n",
    "\n",
    "and, hence, Jeffreys prior is \n",
    "\n",
    "$$p(\\theta) \\propto \\frac{1}{\\sqrt{\\theta(1-\\theta)}} \\propto Beta(\\frac{1}{2},\\frac{1}{2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Priors\n",
    "\n",
    "#### Robust Priors and Mixtures of Conjugate Priors\n",
    "If we have prior assumptions but are not very confident in them, it makes sense to use **robust priors** which have heavy tails and are less peaked around the prior mean! Since they can be computationally disadvantageous, one can resort to **mixtures of conjugate priors** (which are again conjugate) by introducing a latent mixture variable to approximate a desired distribution.\n",
    "\n",
    "In our beta-binomial model, for example, we could introduce a prior \n",
    "\n",
    "$$p(\\theta) = \\frac{1}{2} \\cdot Beta(\\theta|10,10) + \\frac{1}{2} \\cdot Beta(\\theta|20,10)$$\n",
    "\n",
    "This would allow us to model a situtation where we believe the coin is either fair *or* biased towards heads! It is easy to show that the posterior would also be a mixture of $Beta$ dsitributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Frequentist Statistics\n",
    "\n",
    "Frequentist statistics **avoids priors and using the Bayes rule** by using sampling distributions instead of treating parameters as random variables. The **sampling distribution** is the distribution of an estimator when applied to multiple datasets sampled from the true (but unknown) distribution. \n",
    "\n",
    "Frequentist statistics is the **dominant paradigm used in machine learning**. \n",
    "\n",
    "We will discuss a few basic concepts of frequentist statistics for reasons of comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Frequentist Statistics\n",
    "#### The Sampling Distribution\n",
    "\n",
    "To compute a parameter estimate $\\hat \\theta$, we apply an estimator $\\Gamma$ to some dataset $X$: $\\hat \\theta = \\Gamma(X)$. $\\theta$ is fixed. $X$ is random. (In the Bayesian framework $\\theta$ is random and the data is fixed.) Uncertainty is measured by the sampling distribution of the estimator.\n",
    "\n",
    "One way to approximate the sampling distribution from $X$ is the **bootstrap** which repeatedly samples (either with replacement or parametric using $\\hat \\theta$) from the dataset $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Frequentist Statistics\n",
    "#### Model Selection\n",
    "\n",
    "Again, in frequentist theory the parameter is fixed and the data is random and in Bayesian theory the parameter is random, Thus, frequentist decision theory relies on $p(X|\\theta^*)$ ($\\theta^*$ being the \"true\" parameter) while Bayesian theory relies on $p(\\theta|X,\\epsilon)$. Note that $\\theta^*$ is unkown. This is not an issue in the Bayesian approach where we average over the unkown parameter and condition on the data.\n",
    "\n",
    "Frequentist statistics can therefore not directly select the best estimator for an unkown parameter $\\theta$. It circumvents this problem by looking at a situation where observable quantaties (think input features to a supervised classification problem) and their true responses (think corresponding labels) are available. \n",
    "\n",
    "This gives rise to the framework of **Empircal Risk Minimization**. The risk can be upper-bounded using **Statistical Learning Theory** (e.g. using **Vapnik-Chervonenkis** dimension etc.). Estimators are chosen using **cross-validation (CV)**. I assume familiarity with these topics and do not provide further details, but want to emphasize the different perspectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Features of Frequentist Statistics\n",
    "\n",
    "Frequentist statistics has many flaws. Mainly that when computing likelihoods, it relies on some future, hypothetical distribution instead of only observable data as in the case of Bayesian statistics. \n",
    "\n",
    "This somewhat unintitive approach is, however, very successful for a reason. It is often computationally more efficient and flexible. Also, remember that frequentist and Bayesian statistics lead to similar or the same results in a wide variety of scenarios! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part I - Recap of Bayesian ML\n",
    "# Further reading\n",
    "\n",
    "The previous slides only provide a brief summary of some(!) of the basic concepts and terminology encountered in Bayesian Statistics. If you are unfamiliar with many of these concepts, I recommend a look at \"Bayesian Data Analysis\" by Gelman et al. and Murphy's \"Machine Learning (A Probabilistic Perspective)\" before moving on. A lot of the previous slides follow their presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018\n",
    "# Part II - Latent Variable Models and the EM Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part II - Latent Variable Models and the EM Algorithm\n",
    "# Kullback-Leibler Divergence\n",
    "\n",
    "#### Motivation\n",
    "In Part I, it was mentioned that we often want to find computationally more efficient approximation to distributions like the posterior. Therefore, we need a measure of dissimilarity between two distributions. This is what the **Kullback-Leibler (KL) divergence** provides. Before we recap the definition and essential properties, we give a brief review of the concept of **entropy**, which is closely related to the KL divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Notation**: We will denote the entropy of a random variable $X$ as $\\mathbb{H}(X)$ and the KL divergence by $\\mathbb{KL}(p||q)$ for two distributions $p$ and $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part II - Latent Variable Models and the EM Algorithm\n",
    "#### Entropy\n",
    "\n",
    "The entropy of a random variable $X$ with distribution $p$ is an uncertainty measure:\n",
    "\n",
    "$$\\mathbb{H}(X) \\mathrel{\\vcenter{:=}} -\\mathbb{E}\\log(p)$$\n",
    "\n",
    "For a discrete variable this would be\n",
    "\n",
    "$$\\mathbb{H}(X) = - \\sum_{n=1}^N p(X=n) \\log\\left(p(X=n)\\right)$$\n",
    "\n",
    "The most common choice for the base of the logarithm is 2. It is then said that the entropy is measured in **bits**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part II - Latent Variable Models and the EM Algorithm\n",
    "#### Entropy\n",
    "\n",
    "The uniform distribution has maximum entropy (because every value is equally likely, which leads to maximum uncertainty). A discrete distribution with $p(X=d)=1$ has minimum entropy because there is no uncertainty about its distribution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next we will further illustrate this idea by looking at the **binary entropy function** for a binary variable $X$ that can take two values $0$ and $1$ with $p(X=1)=\\theta = 1-p(X=0)$.\n",
    "\n",
    "$$\\mathbb{H}(X) = -\\sum_{n=0}^1 p(X=n)\\log(p(X=n)) = -\\theta\\log\\theta-(1-\\theta)\\log(1-\\theta)$$\n",
    "\n",
    "For which $\\theta$ do we achieve maximum and minimum entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "def binary_cross_entropy(theta):\n",
    "    return -theta*np.log2(theta)-(1-theta)*np.log2(1-theta)\n",
    "\n",
    "theta = np.linspace(2**-15,1, 1000, endpoint=False)\n",
    "ax.plot(theta, binary_cross_entropy(theta), 'r-', lw=2)\n",
    "ax.set_xlabel(r\"$P(X=1) = \\theta$\")\n",
    "ax.set_title(\"Entropy of Bernoulli Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part II - Latent Variable Models and the EM Algorithm\n",
    "#### Entropy\n",
    "\n",
    "This makes intuitive sense. If the probability of heads or tails is 1, there is no uncertainty about the result of the next coin flip. The uncertainty is maximal when both outcomes are equally likely for $\\theta = 0.5$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part II - Latent Variable Models and the EM Algorithm\n",
    "#### Entropy\n",
    "\n",
    "From an information theory background, $\\log_2$ is a natural choice. We saw above that a fair coin toss has an entropy of 1. Similarly, $n$ (fair) coin tosses have an entropy of $n$ bits. Note that rare events have lower entropy because they are less \"surprising\" and carry less information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part II - Latent Variable Models and the EM Algorithm\n",
    "#### KL divergence\n",
    "\n",
    "$$\\mathbb{KL}(q||p) \\mathrel{\\vcenter{:=}} \\mathbb{E}_q \\log\\frac{q(x)}{p(x)} = \\int{q(x)\\log\\frac{q(x)}{p(x)} dx} \\, \\text{ or (in the discrete case) } \\, \\sum_{n=1}^N q(x_n) \\log\\frac{q(x_n)}{p(x_n)} $$\n",
    "\n",
    "Note that the KL divergence is **not symmetric** and $q$ and $p$ have to be **defined over the same domain**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we define the **cross-entropy** as $\\mathbb{H}(q,p) \\mathrel{\\vcenter{:=}} - \\mathbb{E}_q \\log p(x)$ we can decompose the KL divergence into two parts:\n",
    "\n",
    "$$\\mathbb{KL}(q||p) \\mathrel{\\vcenter{:=}} \\mathbb{E}_q \\log\\frac{q(x)}{p(x)} = \\mathbb{E}_q \\log q(x) - \\mathbb{E}_q \\log p(x)= -\\mathbb{H}(q) + \\mathbb{H}(q,p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part II - Latent Variable Models and the EM Algorithm\n",
    "#### KL divergence\n",
    "\n",
    "We can **interpret** this difference between cross-entropy and entropy **as the number of extra bits** needed to describe the data coming from distribution $q$ when we use $p$ instead of the true distribution $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Applying **Jensen's inequality** to the logarithm, one can easily show that **the KL divergence is non-negative**. (This should make sense if we keep in mind the *extra* bit interpretation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, remembering our goal of approximating one distribution with another, what would be the **effect of minimizing the KL divergence with respect to $q$**? \n",
    "\n",
    "From the definition $\\int{q(x)\\log\\frac{q(x)}{p(x)} dx}$ we can see that the approximation needs to be particularly good where $q(x)$ has large values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "© Olaf Wied 2018 \n",
    "\n",
    "Part II - Latent Variable Models and the EM Algorithm\n",
    "\n",
    "# Latent Variable Models"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
